from pinecone import Pinecone, ServerlessSpec
from dotenv import load_dotenv
import os
import logging
import json
from langchain_pinecone import PineconeVectorStore
from pathlib import Path
from langchain_huggingface import HuggingFaceEmbeddings 

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("dbconection")


class DB_Pinecone():
    def __init__(self,dbname,key):
        self.pc = None
        self.index = None
        self.DBname = dbname
        self.api_key = key
        self.embed_model = HuggingFaceEmbeddings(
            model_name="intfloat/multilingual-e5-large", # ì˜ˆë¥¼ ë“¤ì–´ "sentence-transformers/all-MiniLM-L6-v2"
            model_kwargs={"trust_remote_code":True}
        )

    def create_connection(self):
        self.pc = Pinecone(api_key=self.api_key, environment="AWS")
        self.index = self.pc.Index(self.DBname)

    def status(self):
        logger.info(f"ğŸ¤– DB ìƒíƒœë¥¼ ë³´ê³ í•©ë‹ˆë‹¤. \n:{self.index.describe_index_stats()}")

    def input_json_data(self,data):
        logger.info("ğŸ¤– DB ì…ë ¥ì„ ì‹œë„í•©ë‹ˆë‹¤. ")
        
        items = self.json_to_vector(data)
        # Pineconeì— ì—…ì„œíŠ¸
        self.index.upsert(
            namespace=self.DBname,
            vectors=items
        )
        
        logger.info(f"ğŸ¤– {len(items)}ê°œ í•­ëª© // {data} ë¥¼ ì •ìƒì ìœ¼ë¡œ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.. ")
        
    def json_to_vector(self,json_file):

        # ì¸ë±ìŠ¤ ì°¸ì¡°
        index = self.index

        # JSON íŒŒì¼ ì½ê¸°
        raw = json.loads(Path(json_file).read_text(encoding='utf-8'))
        records = raw['ê¸°ìˆ ']['jsonArray']

        # ë²¡í„°í™” ë° ì—…ì„œíŠ¸ ì¤€ë¹„
        items = []

        for idx, record in enumerate(records):
            text = record['bsnsSumryCn']
            
            # í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            vector = self.embed_model.embed_query(text)
            
            # ID êµ¬ì„±
            rec_id = f"{record['pblancId']}#{idx}"
            
            # metadata êµ¬ì„±
            metadata = {
                "title": record.get("pblancNm", ""),
                "summary" : record.get('bsnsSumryCn'),
                "region": record.get("jrsdInsttNm", ""),
                "hashtags": record.get("hashtags", ""),
                "file_path": record.get("fileNm", "")
            }
            
            items.append({
                "id": rec_id,
                "values": vector,
                "metadata": metadata
            })
        
        return items

    def search_database(self,query:str,top_k:int):
        index = self.index

        # ìì—°ì–´ ì§ˆì˜ë¡œ ì§ì ‘ ê²€ìƒ‰
        response = index.search(
            namespace=self.DBname,
            query={
                "top_k": top_k,
                "inputs": {"text": query},
            },
            fields=["summary","title"]
        )
        print(response)
        print("\n\n")
        '''
        query = self.pc.inference.embed(
                model="llama-text-embed-v2",
                inputs=[query],
                parameters={"input_type": "passage", "truncate": "END"}
            )
        filtered_results = index.search(
            namespace=self.DBname, 
            query={
                "inputs": {"text": query}, 
                "top_k": top_k,
                #"filter": {"document_id": "document1"}
            },
            fields=["values","metadata"]
        )

        print(filtered_results)
        '''

if __name__ == "__main__":
    load_dotenv()
    pinecone_db = DB_Pinecone("kt-agent",os.getenv("PINECONE_API_KEY"))
    pinecone_db.create_connection()
    pinecone_db.status()
    #pinecone_db.input_json_data("src/data/all_categories.json")
    pinecone_db.search_database("ì œì¡° ê¸°ìˆ ê³¼ AI ê´€ë ¨ëœ ê±° ë³´ì—¬ì¤˜",30)    